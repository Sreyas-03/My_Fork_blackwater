{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import glob, pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from qiskit import transpile\n",
    "from qiskit import execute\n",
    "from qiskit.providers.fake_provider import FakeLima\n",
    "from qiskit.primitives import Estimator\n",
    "from qiskit.circuit.random import random_circuit\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.nn.functional import dropout\n",
    "\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, Linear, ChebConv, SAGEConv\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from blackwater.data.loaders.exp_val import CircuitGraphExpValMitigationDataset\n",
    "from blackwater.data.generators.exp_val import exp_value_generator\n",
    "from blackwater.data.utils import generate_random_pauli_sum_op\n",
    "from blackwater.library.ngem.estimator import ngem\n",
    "\n",
    "from qiskit.quantum_info import random_clifford\n",
    "\n",
    "import random\n",
    "from qiskit.circuit.library import HGate, SdgGate\n",
    "from qiskit.circuit import ClassicalRegister\n",
    "\n",
    "from blackwater.data.utils import (\n",
    "    generate_random_pauli_sum_op,\n",
    "    create_estimator_meas_data,\n",
    "    circuit_to_graph_data_json,\n",
    "    get_backend_properties_v1,\n",
    "    encode_pauli_sum_op,\n",
    "    create_meas_data_from_estimators\n",
    ")\n",
    "from blackwater.data.generators.exp_val import ExpValueEntry\n",
    "from blackwater.metrics.improvement_factor import improvement_factor, Trial, Problem\n",
    "\n",
    "from qiskit_aer import AerSimulator, QasmSimulator\n",
    "from qiskit.providers.fake_provider import FakeMontreal, FakeLima, FakeBelem\n",
    "\n",
    "from torch_geometric.nn import (\n",
    "    GCNConv,\n",
    "    TransformerConv,\n",
    "    GATv2Conv,\n",
    "    global_mean_pool,\n",
    "    Linear,\n",
    "    ChebConv,\n",
    "    SAGEConv,\n",
    "    ASAPooling,\n",
    "    dense_diff_pool,\n",
    "    avg_pool_neighbor_x\n",
    ")\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import to_dense_adj, to_dense_batch\n",
    "\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit.library import U3Gate, CZGate, PhaseGate, CXGate\n",
    "from mbd_utils import construct_random_clifford, cal_z_exp, calc_imbalance, cal_all_z_exp, construct_mbl_circuit, generate_disorder\n",
    "from gnn import ExpValCircuitGraphModel\n",
    "plt.style.use({'figure.facecolor':'white'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "backend1 = FakeLima()\n",
    "backend2 = FakeBelem()\n",
    "properties1 = get_backend_properties_v1(backend1)\n",
    "properties2 = get_backend_properties_v1(backend2)\n",
    "\n",
    "## Local\n",
    "backend_ideal = QasmSimulator() # Noiseless\n",
    "backend1_noisy = AerSimulator.from_backend(backend1) # Noisy\n",
    "backend2_noisy = AerSimulator.from_backend(backend2) # Noisy\n",
    "\n",
    "run_config_ideal = {'shots': 10000, 'backend': backend_ideal, 'name': 'ideal'}\n",
    "run_config_noisy1 = {'shots': 10000, 'backend': backend1_noisy, 'name': 'noisy'}\n",
    "run_config_noisy2 = {'shots': 10000, 'backend': backend2_noisy, 'name': 'noisy'}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train on Backend 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "train_paths = [\n",
    "    f'./data/circ_parsed_pyg_data/train/fakelima_depth{i}.json' for i in range(1, 10)\n",
    "]\n",
    "\n",
    "val_paths = [\n",
    "    f'./data/circ_parsed_pyg_data/val/fakelima/fakelima_depth{i}.json' for i in range(1, 10)\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[768, 22], edge_index=[2, 1643], edge_attr=[875, 3], y=[32, 1, 5], observable=[32, 0], circuit_depth=[32, 1], noisy_0=[32, 1, 5], batch=[768], ptr=[33])\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    CircuitGraphExpValMitigationDataset(\n",
    "        train_paths,\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    CircuitGraphExpValMitigationDataset(\n",
    "        val_paths,\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "for data in train_loader:\n",
    "    print(data)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "model = ExpValCircuitGraphModel(\n",
    "    num_node_features=22,\n",
    "    hidden_channels=15,\n",
    "    exp_value_size=5\n",
    ")\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer,\n",
    "                              'min',\n",
    "                              factor=0.1,\n",
    "                              patience=15,\n",
    "                              verbose=True,\n",
    "                              min_lr=0.00001)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13676 9024 3616\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad), len(train_loader) * BATCH_SIZE, len(val_loader) * BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "Model training:   0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "74c720a83b454a53ac36120b0a5ea6f9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00039: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 00055: reducing learning rate of group 0 to 1.0000e-05.\n"
     ]
    }
   ],
   "source": [
    "min_valid_loss = np.inf\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "N_EPOCHS = 100\n",
    "\n",
    "progress = tqdm_notebook(range(N_EPOCHS), desc='Model training', leave=True)\n",
    "for epoch in progress:\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out = model(\n",
    "            data.noisy_0,\n",
    "            data.observable,\n",
    "            data.circuit_depth,\n",
    "            data.x,\n",
    "            data.edge_index,\n",
    "            data.batch\n",
    "        )\n",
    "        loss = criterion(out, torch.squeeze(data.y, 1))\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    valid_loss = 0.0\n",
    "    model.eval()\n",
    "    for i, data in enumerate(val_loader):\n",
    "        out = model(\n",
    "            data.noisy_0,\n",
    "            data.observable,\n",
    "            data.circuit_depth,\n",
    "            data.x,\n",
    "            data.edge_index,\n",
    "            data.batch)\n",
    "        loss = criterion(out, torch.squeeze(data.y, 1))\n",
    "\n",
    "        valid_loss += loss.item()\n",
    "\n",
    "    scheduler.step(valid_loss)\n",
    "\n",
    "    if epoch >= 1:\n",
    "        train_losses.append(train_loss / len(train_loader))\n",
    "        val_losses.append(valid_loss / len(val_loader))\n",
    "\n",
    "        progress.set_description(f\"{round(train_losses[-1], 5)}, {round(val_losses[-1], 5)}\")\n",
    "        progress.refresh()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"train_loss\")\n",
    "plt.plot(val_losses, label=\"val_loss\")\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_path = './model/finetuning/train_fakelima.pth'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "to_save = {'train_losses': train_losses, 'val_losses': val_losses}\n",
    "with open('.'+model_path.split('.')[1]+'.pk', 'wb') as handle:\n",
    "    pickle.dump(to_save, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test on Backend 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dfs = {}\n",
    "model.eval()\n",
    "for d in range(1, 10):\n",
    "    test_paths = [\n",
    "        f'./data/circ_parsed_pyg_data/val/fakebelem_depth{d}.json'\n",
    "    ]\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        CircuitGraphExpValMitigationDataset(\n",
    "            test_paths,\n",
    "        ),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    distances = []\n",
    "    for i, data in enumerate(val_loader):\n",
    "        out = model(data.noisy_0, data.observable, data.circuit_depth, data.x, data.edge_index, data.batch)\n",
    "\n",
    "        for ideal, noisy, ngm_mitigated in zip(\n",
    "            data.y.tolist(),\n",
    "            data.noisy_0.tolist(),\n",
    "            out.tolist()\n",
    "        ):\n",
    "            ideal = np.mean(ideal)\n",
    "            noisy = np.mean(noisy)\n",
    "            ngm_mitigated = np.mean(ngm_mitigated)\n",
    "            distances.append({\n",
    "                \"ideal\": ideal,\n",
    "                \"noisy\": noisy,\n",
    "                \"ngm_mitigated\": ngm_mitigated,\n",
    "                \"dist_noisy\": np.abs(ideal - noisy),\n",
    "                \"dist_ngm\": np.abs(ideal - ngm_mitigated),\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(distances)\n",
    "    dfs[d] = df\n",
    "\n",
    "# sns.boxplot(data=df[[\"dist_noisy\", \"dist_ngm\"]], orient=\"h\", showfliers = False)\n",
    "# plt.title(\"Dist to ideal exp value\")\n",
    "# plt.show()\n",
    "#\n",
    "# sns.histplot([df['ideal'], df['noisy'], df[\"ngm_mitigated\"]], kde=True, bins=40)\n",
    "# plt.title(\"Exp values distribution\")\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1, 10), df['dist_noisy'])\n",
    "plt.plot(np.arange(1, 10), df['dist_ngm'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Finetune on Backend 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "finetune_paths = [\n",
    "    f'./data/circ_parsed_pyg_data/finetune/fakebelem_depth{i}.json' for i in range(1, 10)\n",
    "]\n",
    "\n",
    "test_paths = [\n",
    "    f'./data/circ_parsed_pyg_data/val/fakebelem_depth{i}.json' for i in range(1, 10)\n",
    "]\n",
    "\n",
    "finetune_loader = DataLoader(\n",
    "    CircuitGraphExpValMitigationDataset(\n",
    "        finetune_paths,\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    CircuitGraphExpValMitigationDataset(\n",
    "        test_paths,\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "min_valid_loss = np.inf\n",
    "\n",
    "finetune_losses = []\n",
    "test_losses = []\n",
    "\n",
    "N_EPOCHS = 100\n",
    "\n",
    "progress = tqdm_notebook(range(N_EPOCHS), desc='Model training', leave=True)\n",
    "for epoch in progress:\n",
    "    finetune_loss = 0.0\n",
    "    model.train()\n",
    "    for i, data in enumerate(finetune_losses):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out = model(\n",
    "            data.noisy_0,\n",
    "            data.observable,\n",
    "            data.circuit_depth,\n",
    "            data.x,\n",
    "            data.edge_index,\n",
    "            data.batch\n",
    "        )\n",
    "        loss = criterion(out, torch.squeeze(data.y, 1))\n",
    "\n",
    "        finetune_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    test_loss = 0.0\n",
    "    model.eval()\n",
    "    for i, data in enumerate(test_loader):\n",
    "        out = model(\n",
    "            data.noisy_0,\n",
    "            data.observable,\n",
    "            data.circuit_depth,\n",
    "            data.x,\n",
    "            data.edge_index,\n",
    "            data.batch)\n",
    "        loss = criterion(out, torch.squeeze(data.y, 1))\n",
    "\n",
    "        test_loss += loss.item()\n",
    "\n",
    "    scheduler.step(test_loss)\n",
    "\n",
    "    if epoch >= 1:\n",
    "        train_losses.append(finetune_loss / len(finetune_loader))\n",
    "        val_losses.append(test_loss / len(test_loader))\n",
    "\n",
    "        progress.set_description(f\"{round(finetune_losses[-1], 5)}, {round(test_losses[-1], 5)}\")\n",
    "        progress.refresh()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test on Backend 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train on Backend 2 from scratch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test on Backend 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
