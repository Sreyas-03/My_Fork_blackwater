{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from qiskit import transpile\n",
    "from qiskit import execute, QuantumRegister, ClassicalRegister, Aer\n",
    "from qiskit.providers.fake_provider import FakeLima\n",
    "from qiskit.primitives import Estimator\n",
    "from qiskit.circuit.random import random_circuit\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.nn.functional import dropout\n",
    "\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, Linear, ChebConv, SAGEConv\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from blackwater.data.loaders.exp_val import CircuitGraphExpValMitigationDataset\n",
    "from blackwater.data.generators.exp_val import exp_value_generator\n",
    "from blackwater.data.utils import generate_random_pauli_sum_op\n",
    "from blackwater.library.ngem.estimator import ngem\n",
    "\n",
    "from qiskit.quantum_info import random_clifford\n",
    "\n",
    "import random\n",
    "from qiskit.circuit.library import HGate, SdgGate\n",
    "from qiskit.circuit import ClassicalRegister\n",
    "\n",
    "from blackwater.data.utils import (\n",
    "    generate_random_pauli_sum_op,\n",
    "    create_estimator_meas_data,\n",
    "    circuit_to_graph_data_json,\n",
    "    get_backend_properties_v1,\n",
    "    encode_pauli_sum_op,\n",
    "    create_meas_data_from_estimators\n",
    ")\n",
    "from blackwater.data.generators.exp_val import ExpValueEntry\n",
    "from blackwater.metrics.improvement_factor import improvement_factor, Trial, Problem\n",
    "\n",
    "from qiskit_aer import AerSimulator, QasmSimulator\n",
    "from qiskit.providers.fake_provider import FakeMontreal, FakeLima\n",
    "\n",
    "from torch_geometric.nn import (\n",
    "    GCNConv,\n",
    "    TransformerConv,\n",
    "    GATv2Conv,\n",
    "    global_mean_pool,\n",
    "    Linear,\n",
    "    ChebConv,\n",
    "    SAGEConv,\n",
    "    ASAPooling,\n",
    "    dense_diff_pool,\n",
    "    avg_pool_neighbor_x\n",
    ")\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import to_dense_adj, to_dense_batch\n",
    "\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit.library import U3Gate, CZGate, PhaseGate, CXGate\n",
    "from mbd_utils import construct_random_clifford, cal_z_exp, calc_imbalance, cal_all_z_exp, construct_mbl_circuit, generate_disorder\n",
    "from gnn import ExpValCircuitGraphModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "backend = FakeMontreal()\n",
    "properties = get_backend_properties_v1(backend)\n",
    "\n",
    "## Local\n",
    "backend_ideal = QasmSimulator() # Noiseless\n",
    "backend_noisy = AerSimulator.from_backend(backend) # Noisy\n",
    "\n",
    "run_config_ideal = {'shots': 10000, 'backend': backend_ideal, 'name': 'ideal'}\n",
    "run_config_noisy = {'shots': 10000, 'backend': backend_noisy, 'name': 'noisy'}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "train_paths = [\n",
    "    './data/tiling/train/step6_q0-q3_total8_seed0.json',\n",
    "    './data/tiling/train/step6_q2-q5_total8_seed1.json',\n",
    "    './data/tiling/train/step6_q4-q7_total8_seed2.json'\n",
    "]\n",
    "\n",
    "val_paths = [\n",
    "     'data/tiling/val/step6_q0-q7_total8_seed0.json'\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[5910, 22], edge_index=[2, 12236], edge_attr=[6326, 3], y=[32, 1, 8], observable=[32, 0], circuit_depth=[32, 1], noisy_0=[32, 1, 8], batch=[5910], ptr=[33])\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    CircuitGraphExpValMitigationDataset(\n",
    "        train_paths,\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    CircuitGraphExpValMitigationDataset(\n",
    "        val_paths,\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "for data in train_loader:\n",
    "    print(data)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "model = ExpValCircuitGraphModel(\n",
    "    num_node_features=22,\n",
    "    hidden_channels=15,\n",
    "    exp_value_size=8\n",
    ")\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer,\n",
    "                              'min',\n",
    "                              factor=0.1,\n",
    "                              patience=15,\n",
    "                              verbose=True,\n",
    "                              min_lr=0.00001)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13769\n",
      "3008 1024\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "print(len(train_loader) * BATCH_SIZE, len(val_loader) * BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "Model training:   0%|          | 0/100 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ce2394a5b8454e19aa1de902184f4d54"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00037: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 00053: reducing learning rate of group 0 to 1.0000e-05.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [8]\u001B[0m, in \u001B[0;36m<cell line: 9>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     31\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(val_loader):\n\u001B[0;32m---> 33\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     34\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnoisy_0\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     35\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mobservable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     36\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcircuit_depth\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     37\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     38\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     39\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     40\u001B[0m     loss \u001B[38;5;241m=\u001B[39m criterion(out, torch\u001B[38;5;241m.\u001B[39msqueeze(data\u001B[38;5;241m.\u001B[39my, \u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m     42\u001B[0m     valid_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[0;32m/opt/anaconda3/envs/ngem/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/GitHub/blackwater/docs/tutorials/gnn.py:101\u001B[0m, in \u001B[0;36mExpValCircuitGraphModel.forward\u001B[0;34m(self, exp_value, observable, circuit_depth, nodes, edge_index, batch)\u001B[0m\n\u001B[1;32m     97\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m     98\u001B[0m             exp_value, observable,\n\u001B[1;32m     99\u001B[0m             circuit_depth, nodes,\n\u001B[1;32m    100\u001B[0m             edge_index, batch):\n\u001B[0;32m--> 101\u001B[0m     graph \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransformer1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnodes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    102\u001B[0m     graph, edge_index, _, batch, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooling1(\n\u001B[1;32m    103\u001B[0m         graph, edge_index, batch\u001B[38;5;241m=\u001B[39mbatch\n\u001B[1;32m    104\u001B[0m     )\n\u001B[1;32m    106\u001B[0m     graph \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransformer2(graph, edge_index)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/ngem/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m/opt/anaconda3/envs/ngem/lib/python3.10/site-packages/torch_geometric/nn/conv/transformer_conv.py:176\u001B[0m, in \u001B[0;36mTransformerConv.forward\u001B[0;34m(self, x, edge_index, edge_attr, return_attention_weights)\u001B[0m\n\u001B[1;32m    173\u001B[0m value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlin_value(x[\u001B[38;5;241m0\u001B[39m])\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, H, C)\n\u001B[1;32m    175\u001B[0m \u001B[38;5;66;03m# propagate_type: (query: Tensor, key:Tensor, value: Tensor, edge_attr: OptTensor) # noqa\u001B[39;00m\n\u001B[0;32m--> 176\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpropagate\u001B[49m\u001B[43m(\u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquery\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    177\u001B[0m \u001B[43m                     \u001B[49m\u001B[43medge_attr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medge_attr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    179\u001B[0m alpha \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_alpha\n\u001B[1;32m    180\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_alpha \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/ngem/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:437\u001B[0m, in \u001B[0;36mMessagePassing.propagate\u001B[0;34m(self, edge_index, size, **kwargs)\u001B[0m\n\u001B[1;32m    435\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m res \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    436\u001B[0m         msg_kwargs \u001B[38;5;241m=\u001B[39m res[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(res, \u001B[38;5;28mtuple\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m res\n\u001B[0;32m--> 437\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmessage\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmsg_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    438\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_message_forward_hooks\u001B[38;5;241m.\u001B[39mvalues():\n\u001B[1;32m    439\u001B[0m     res \u001B[38;5;241m=\u001B[39m hook(\u001B[38;5;28mself\u001B[39m, (msg_kwargs, ), out)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/ngem/lib/python3.10/site-packages/torch_geometric/nn/conv/transformer_conv.py:216\u001B[0m, in \u001B[0;36mTransformerConv.message\u001B[0;34m(self, query_i, key_j, value_j, edge_attr, index, ptr, size_i)\u001B[0m\n\u001B[1;32m    213\u001B[0m     key_j \u001B[38;5;241m=\u001B[39m key_j \u001B[38;5;241m+\u001B[39m edge_attr\n\u001B[1;32m    215\u001B[0m alpha \u001B[38;5;241m=\u001B[39m (query_i \u001B[38;5;241m*\u001B[39m key_j)\u001B[38;5;241m.\u001B[39msum(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m/\u001B[39m math\u001B[38;5;241m.\u001B[39msqrt(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mout_channels)\n\u001B[0;32m--> 216\u001B[0m alpha \u001B[38;5;241m=\u001B[39m \u001B[43msoftmax\u001B[49m\u001B[43m(\u001B[49m\u001B[43malpha\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mptr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize_i\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    217\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_alpha \u001B[38;5;241m=\u001B[39m alpha\n\u001B[1;32m    218\u001B[0m alpha \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mdropout(alpha, p\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout, training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/ngem/lib/python3.10/site-packages/torch_geometric/utils/softmax.py:62\u001B[0m, in \u001B[0;36msoftmax\u001B[0;34m(src, index, ptr, num_nodes, dim)\u001B[0m\n\u001B[1;32m     60\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m index \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     61\u001B[0m     N \u001B[38;5;241m=\u001B[39m maybe_num_nodes(index, num_nodes)\n\u001B[0;32m---> 62\u001B[0m     src_max \u001B[38;5;241m=\u001B[39m \u001B[43mscatter\u001B[49m\u001B[43m(\u001B[49m\u001B[43msrc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mN\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduce\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmax\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     63\u001B[0m     src_max \u001B[38;5;241m=\u001B[39m src_max\u001B[38;5;241m.\u001B[39mindex_select(dim, index)\n\u001B[1;32m     64\u001B[0m     out \u001B[38;5;241m=\u001B[39m (src \u001B[38;5;241m-\u001B[39m src_max)\u001B[38;5;241m.\u001B[39mexp()\n",
      "File \u001B[0;32m/opt/anaconda3/envs/ngem/lib/python3.10/site-packages/torch_scatter/scatter.py:160\u001B[0m, in \u001B[0;36mscatter\u001B[0;34m(src, index, dim, out, dim_size, reduce)\u001B[0m\n\u001B[1;32m    158\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m scatter_min(src, index, dim, out, dim_size)[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    159\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m reduce \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m--> 160\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mscatter_max\u001B[49m\u001B[43m(\u001B[49m\u001B[43msrc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim_size\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    161\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    162\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/ngem/lib/python3.10/site-packages/torch_scatter/scatter.py:72\u001B[0m, in \u001B[0;36mscatter_max\u001B[0;34m(src, index, dim, out, dim_size)\u001B[0m\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mscatter_max\u001B[39m(\n\u001B[1;32m     69\u001B[0m         src: torch\u001B[38;5;241m.\u001B[39mTensor, index: torch\u001B[38;5;241m.\u001B[39mTensor, dim: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m     70\u001B[0m         out: Optional[torch\u001B[38;5;241m.\u001B[39mTensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     71\u001B[0m         dim_size: Optional[\u001B[38;5;28mint\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[torch\u001B[38;5;241m.\u001B[39mTensor, torch\u001B[38;5;241m.\u001B[39mTensor]:\n\u001B[0;32m---> 72\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtorch_scatter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscatter_max\u001B[49m\u001B[43m(\u001B[49m\u001B[43msrc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim_size\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/ngem/lib/python3.10/site-packages/torch/_ops.py:442\u001B[0m, in \u001B[0;36mOpOverloadPacket.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    437\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    438\u001B[0m     \u001B[38;5;66;03m# overloading __call__ to ensure torch.ops.foo.bar()\u001B[39;00m\n\u001B[1;32m    439\u001B[0m     \u001B[38;5;66;03m# is still callable from JIT\u001B[39;00m\n\u001B[1;32m    440\u001B[0m     \u001B[38;5;66;03m# We save the function ptr as the `op` attribute on\u001B[39;00m\n\u001B[1;32m    441\u001B[0m     \u001B[38;5;66;03m# OpOverloadPacket to access it here.\u001B[39;00m\n\u001B[0;32m--> 442\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_op\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "min_valid_loss = np.inf\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "N_EPOCHS = 100\n",
    "\n",
    "progress = tqdm_notebook(range(N_EPOCHS), desc='Model training', leave=True)\n",
    "for epoch in progress:\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out = model(\n",
    "            data.noisy_0,\n",
    "            data.observable,\n",
    "            data.circuit_depth,\n",
    "            data.x,\n",
    "            data.edge_index,\n",
    "            data.batch\n",
    "        )\n",
    "        loss = criterion(out, torch.squeeze(data.y, 1))\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    valid_loss = 0.0\n",
    "    model.eval()\n",
    "    for i, data in enumerate(val_loader):\n",
    "        out = model(\n",
    "            data.noisy_0,\n",
    "            data.observable,\n",
    "            data.circuit_depth,\n",
    "            data.x,\n",
    "            data.edge_index,\n",
    "            data.batch)\n",
    "        loss = criterion(out, torch.squeeze(data.y, 1))\n",
    "\n",
    "        valid_loss += loss.item()\n",
    "\n",
    "    scheduler.step(valid_loss)\n",
    "\n",
    "    if epoch >= 1:\n",
    "        train_losses.append(train_loss / len(train_loader))\n",
    "        val_losses.append(valid_loss / len(val_loader))\n",
    "\n",
    "        progress.set_description(f\"{round(train_losses[-1], 5)}, {round(val_losses[-1], 5)}\")\n",
    "        progress.refresh()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label=\"train_loss\")\n",
    "plt.plot(val_losses, label=\"val_loss\")\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "model_path = './model/tiling/tiling_mbd.pth'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), model_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle\n",
    "to_save = {'train_losses': train_losses, 'val_losses': val_losses}\n",
    "with open('.' + model_path.split('.')[1] + '.pk', 'wb') as handle:\n",
    "    pickle.dump(to_save, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
