{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json, os, pickle\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn as nn\n",
    "\n",
    "import qiskit\n",
    "from qiskit import QuantumCircuit, execute\n",
    "from qiskit.compiler import transpile\n",
    "from qiskit_aer import AerSimulator, QasmSimulator\n",
    "from qiskit.converters import circuit_to_dag, dag_to_circuit\n",
    "from qiskit.quantum_info import SparsePauliOp, Operator\n",
    "from qiskit.circuit.library import CXGate, RXGate, IGate, ZGate\n",
    "from qiskit.providers.fake_provider import FakeMontreal, FakeLima\n",
    "\n",
    "from blackwater.data.utils import (\n",
    "    generate_random_pauli_sum_op,\n",
    "    create_estimator_meas_data,\n",
    "    circuit_to_graph_data_json,\n",
    "    get_backend_properties_v1,\n",
    "    encode_pauli_sum_op,\n",
    "    create_meas_data_from_estimators\n",
    ")\n",
    "\n",
    "from mlp import MLP1, MLP2, MLP3, encode_data, fix_random_seed\n",
    "\n",
    "from mbd_utils import cal_z_exp, generate_disorder, construct_mbl_circuit, calc_imbalance, modify_and_add_noise_to_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "backend = FakeLima()\n",
    "properties = get_backend_properties_v1(backend)\n",
    "\n",
    "# Local, coherent noise\n",
    "backend_ideal = QasmSimulator() # Noiseless\n",
    "backend_noisy_coherent, noise_model = modify_and_add_noise_to_model()\n",
    "\n",
    "run_config_ideal = {'shots': 10000, 'backend': backend_ideal, 'name': 'ideal'}\n",
    "run_config_noisy_coherent = {'shots': 10000, 'backend': backend_noisy_coherent, 'name': 'noisy_coherent'}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def load_circuits(data_dir, f_ext='.json'):\n",
    "    circuits = []\n",
    "    ideal_exp_vals = []\n",
    "    noisy_exp_vals = []\n",
    "    data_files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith(f_ext)]\n",
    "    for data_file in tqdm(data_files, leave=True):\n",
    "        if f_ext == '.json':\n",
    "            for entry in json.load(open(data_file, 'r')):\n",
    "                circuits.append(QuantumCircuit.from_qasm_str(entry['circuit']))\n",
    "                ideal_exp_vals.append(entry['ideal_exp_value'])\n",
    "                noisy_exp_vals.append(entry['noisy_exp_values'])\n",
    "        elif f_ext == '.pk':\n",
    "            for entry in pickle.load(open(data_file, 'rb')):\n",
    "                circuits.append(entry['circuit'])\n",
    "                ideal_exp_vals.append(entry['ideal_exp_value'])\n",
    "                noisy_exp_vals.append(entry['noisy_exp_values'])\n",
    "    return circuits, ideal_exp_vals, noisy_exp_vals"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_circuits, train_ideal_exp_vals, train_noisy_exp_vals = load_circuits('./data/mbd_datasets2/theta_0.05pi/train/', '.pk')\n",
    "print(len(train_circuits))\n",
    "\n",
    "test_circuits, test_ideal_exp_vals, test_noisy_exp_vals = load_circuits('./data/mbd_datasets2/theta_0.05pi/val/', '.pk')\n",
    "print(len(test_circuits))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "with open('./data/mbd_datasets2/theta_0.05pi/circuits.pk', 'rb') as infile:\n",
    "    loaded = pickle.load(infile)\n",
    "\n",
    "train_circuits = loaded['train_circuits']\n",
    "test_circuits = loaded['test_circuits']\n",
    "train_ideal_exp_vals = loaded['train_ideal_exp_vals']\n",
    "train_noisy_exp_vals = loaded['train_noisy_exp_vals']\n",
    "test_ideal_exp_vals = loaded['test_ideal_exp_vals']\n",
    "test_noisy_exp_vals = loaded['test_noisy_exp_vals']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "train_noisy_exp_vals = [x[0] for x in train_noisy_exp_vals]\n",
    "test_noisy_exp_vals = [x[0] for x in test_noisy_exp_vals]\n",
    "X_train, y_train = encode_data(train_circuits, properties, train_ideal_exp_vals, train_noisy_exp_vals, num_qubits=4)\n",
    "X_test, y_test = encode_data(test_circuits, properties, test_ideal_exp_vals, test_noisy_exp_vals, num_qubits=4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "y_train = pd.DataFrame(y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "           0         1         2         3\n0        NaN       NaN       NaN       NaN\n1        NaN       NaN       NaN       NaN\n2        NaN       NaN       NaN       NaN\n3        NaN       NaN       NaN       NaN\n4        NaN       NaN       NaN       NaN\n5        NaN       NaN       NaN       NaN\n6        NaN       NaN       NaN       NaN\n7        NaN       NaN       NaN       NaN\n8  -0.221177  0.267191 -0.246187  0.306683\n9        NaN       NaN       NaN       NaN\n10       NaN       NaN       NaN       NaN\n11 -0.221721  0.266496 -0.245470  0.306597\n12 -0.223688  0.268021 -0.246233  0.306636\n13  0.171147 -0.140400  0.096890 -0.114460\n14 -0.181861  0.492776 -0.196124  0.026801\n15 -0.074922  0.173458 -0.132047  0.002872\n16 -0.027246  0.032790 -0.289310  0.045251\n17 -0.004816 -0.004246 -0.084778  0.019740\n18 -0.022025  0.013747 -0.023215  0.083748\n19 -0.056943  0.040633  0.013541  0.082805\n20  0.011119  0.049340  0.018869  0.061809\n21 -0.021649  0.009453  0.032372  0.044198\n22 -0.040460  0.040667  0.007371  0.059739\n23 -0.081722  0.050517 -0.009365  0.058778\n24 -0.162438  0.192382 -0.196478  0.266809\n25 -0.121990  0.189069 -0.117507  0.104649\n26 -0.122175  0.265793 -0.170588  0.130653\n27 -0.110972  0.152781 -0.080548  0.026094\n28 -0.140884  0.165581 -0.053202  0.174081\n29 -0.176092  0.268124 -0.299687  0.183168\n30 -0.054695  0.062520 -0.102137  0.053500\n31 -0.145355  0.101866 -0.178939  0.152740\n32 -0.025873 -0.006891 -0.025152  0.159614\n33 -0.094644  0.043083 -0.057432  0.472273\n34 -0.077695  0.065717 -0.070799  0.525206\n35 -0.020919  0.035044 -0.046988  0.168495\n36 -0.080982  0.031283 -0.051475  0.025868\n37 -0.042291  0.050595 -0.046455 -0.005856\n38 -0.130609  0.192331 -0.149064  0.167152\n39 -0.200170  0.207036 -0.201491  0.269918\n40 -0.027442  0.009640 -0.011093 -0.014325\n41 -0.014901  0.010771 -0.067556 -0.050122\n42 -0.031336  0.008887 -0.001645  0.032516\n43 -0.223638  0.262565 -0.224791  0.271826\n44 -0.109903  0.028009 -0.055617  0.030501\n45 -0.005923  0.003406 -0.004511  0.005363\n46 -0.035652  0.014152 -0.030688  0.056834\n47 -0.027074  0.038261 -0.031222  0.060668\n48 -0.061012  0.017225 -0.075454  0.040993\n49 -0.008414  0.022363  0.000645  0.052911\n50  0.000483  0.035847 -0.025142  0.048907\n51  0.000687  0.034496 -0.016535  0.044112\n52 -0.001524  0.004745 -0.025545  0.055256\n53  0.006656 -0.005867  0.004284 -0.003001\n54  0.282898 -0.212561  0.177731 -0.197258\n55 -0.330145  0.969006 -0.488701  0.156458\n56  0.221306 -0.323007  0.404190 -0.314151\n57 -0.089574  0.112929 -0.146153  0.995696",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>-0.221177</td>\n      <td>0.267191</td>\n      <td>-0.246187</td>\n      <td>0.306683</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>-0.221721</td>\n      <td>0.266496</td>\n      <td>-0.245470</td>\n      <td>0.306597</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>-0.223688</td>\n      <td>0.268021</td>\n      <td>-0.246233</td>\n      <td>0.306636</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.171147</td>\n      <td>-0.140400</td>\n      <td>0.096890</td>\n      <td>-0.114460</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>-0.181861</td>\n      <td>0.492776</td>\n      <td>-0.196124</td>\n      <td>0.026801</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>-0.074922</td>\n      <td>0.173458</td>\n      <td>-0.132047</td>\n      <td>0.002872</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>-0.027246</td>\n      <td>0.032790</td>\n      <td>-0.289310</td>\n      <td>0.045251</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>-0.004816</td>\n      <td>-0.004246</td>\n      <td>-0.084778</td>\n      <td>0.019740</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>-0.022025</td>\n      <td>0.013747</td>\n      <td>-0.023215</td>\n      <td>0.083748</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>-0.056943</td>\n      <td>0.040633</td>\n      <td>0.013541</td>\n      <td>0.082805</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.011119</td>\n      <td>0.049340</td>\n      <td>0.018869</td>\n      <td>0.061809</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>-0.021649</td>\n      <td>0.009453</td>\n      <td>0.032372</td>\n      <td>0.044198</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>-0.040460</td>\n      <td>0.040667</td>\n      <td>0.007371</td>\n      <td>0.059739</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>-0.081722</td>\n      <td>0.050517</td>\n      <td>-0.009365</td>\n      <td>0.058778</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>-0.162438</td>\n      <td>0.192382</td>\n      <td>-0.196478</td>\n      <td>0.266809</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>-0.121990</td>\n      <td>0.189069</td>\n      <td>-0.117507</td>\n      <td>0.104649</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>-0.122175</td>\n      <td>0.265793</td>\n      <td>-0.170588</td>\n      <td>0.130653</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>-0.110972</td>\n      <td>0.152781</td>\n      <td>-0.080548</td>\n      <td>0.026094</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>-0.140884</td>\n      <td>0.165581</td>\n      <td>-0.053202</td>\n      <td>0.174081</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>-0.176092</td>\n      <td>0.268124</td>\n      <td>-0.299687</td>\n      <td>0.183168</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>-0.054695</td>\n      <td>0.062520</td>\n      <td>-0.102137</td>\n      <td>0.053500</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>-0.145355</td>\n      <td>0.101866</td>\n      <td>-0.178939</td>\n      <td>0.152740</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>-0.025873</td>\n      <td>-0.006891</td>\n      <td>-0.025152</td>\n      <td>0.159614</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>-0.094644</td>\n      <td>0.043083</td>\n      <td>-0.057432</td>\n      <td>0.472273</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>-0.077695</td>\n      <td>0.065717</td>\n      <td>-0.070799</td>\n      <td>0.525206</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>-0.020919</td>\n      <td>0.035044</td>\n      <td>-0.046988</td>\n      <td>0.168495</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>-0.080982</td>\n      <td>0.031283</td>\n      <td>-0.051475</td>\n      <td>0.025868</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>-0.042291</td>\n      <td>0.050595</td>\n      <td>-0.046455</td>\n      <td>-0.005856</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>-0.130609</td>\n      <td>0.192331</td>\n      <td>-0.149064</td>\n      <td>0.167152</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>-0.200170</td>\n      <td>0.207036</td>\n      <td>-0.201491</td>\n      <td>0.269918</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>-0.027442</td>\n      <td>0.009640</td>\n      <td>-0.011093</td>\n      <td>-0.014325</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>-0.014901</td>\n      <td>0.010771</td>\n      <td>-0.067556</td>\n      <td>-0.050122</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>-0.031336</td>\n      <td>0.008887</td>\n      <td>-0.001645</td>\n      <td>0.032516</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>-0.223638</td>\n      <td>0.262565</td>\n      <td>-0.224791</td>\n      <td>0.271826</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>-0.109903</td>\n      <td>0.028009</td>\n      <td>-0.055617</td>\n      <td>0.030501</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>-0.005923</td>\n      <td>0.003406</td>\n      <td>-0.004511</td>\n      <td>0.005363</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>-0.035652</td>\n      <td>0.014152</td>\n      <td>-0.030688</td>\n      <td>0.056834</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>-0.027074</td>\n      <td>0.038261</td>\n      <td>-0.031222</td>\n      <td>0.060668</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>-0.061012</td>\n      <td>0.017225</td>\n      <td>-0.075454</td>\n      <td>0.040993</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>-0.008414</td>\n      <td>0.022363</td>\n      <td>0.000645</td>\n      <td>0.052911</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>0.000483</td>\n      <td>0.035847</td>\n      <td>-0.025142</td>\n      <td>0.048907</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>0.000687</td>\n      <td>0.034496</td>\n      <td>-0.016535</td>\n      <td>0.044112</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>-0.001524</td>\n      <td>0.004745</td>\n      <td>-0.025545</td>\n      <td>0.055256</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>0.006656</td>\n      <td>-0.005867</td>\n      <td>0.004284</td>\n      <td>-0.003001</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>0.282898</td>\n      <td>-0.212561</td>\n      <td>0.177731</td>\n      <td>-0.197258</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>-0.330145</td>\n      <td>0.969006</td>\n      <td>-0.488701</td>\n      <td>0.156458</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>0.221306</td>\n      <td>-0.323007</td>\n      <td>0.404190</td>\n      <td>-0.314151</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>-0.089574</td>\n      <td>0.112929</td>\n      <td>-0.146153</td>\n      <td>0.995696</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def correlation_map(X, y):\n",
    "    corr_matrix = np.zeros((X.shape[1], y.shape[1]))\n",
    "    for i, x_col in enumerate(X.columns):\n",
    "        for j, y_col in enumerate(y.columns):\n",
    "            corr_matrix[i, j] = X[x_col].corr(y[y_col])\n",
    "\n",
    "    return pd.DataFrame(corr_matrix, index=X.columns, columns=y.columns)\n",
    "\n",
    "correlation_map(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
