{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import json\n",
    "import glob, pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from qiskit import transpile\n",
    "from qiskit import execute\n",
    "from qiskit.providers.fake_provider import FakeLima\n",
    "from qiskit.primitives import Estimator\n",
    "from qiskit.circuit.random import random_circuit\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.nn.functional import dropout\n",
    "\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, Linear, ChebConv, SAGEConv\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from blackwater.data.loaders.exp_val import CircuitGraphExpValMitigationDataset\n",
    "from blackwater.data.generators.exp_val import exp_value_generator\n",
    "from blackwater.data.utils import generate_random_pauli_sum_op\n",
    "from blackwater.library.ngem.estimator import ngem\n",
    "\n",
    "from qiskit.quantum_info import random_clifford\n",
    "\n",
    "import random\n",
    "from qiskit.circuit.library import HGate, SdgGate\n",
    "from qiskit.circuit import ClassicalRegister\n",
    "\n",
    "from blackwater.data.utils import (\n",
    "    generate_random_pauli_sum_op,\n",
    "    create_estimator_meas_data,\n",
    "    circuit_to_graph_data_json,\n",
    "    get_backend_properties_v1,\n",
    "    encode_pauli_sum_op,\n",
    "    create_meas_data_from_estimators\n",
    ")\n",
    "from blackwater.data.generators.exp_val import ExpValueEntry\n",
    "from blackwater.metrics.improvement_factor import improvement_factor, Trial, Problem\n",
    "\n",
    "from qiskit_aer import AerSimulator, QasmSimulator\n",
    "from qiskit.providers.fake_provider import FakeMontreal, FakeLima, FakeBelem\n",
    "\n",
    "from torch_geometric.nn import (\n",
    "    GCNConv,\n",
    "    TransformerConv,\n",
    "    GATv2Conv,\n",
    "    global_mean_pool,\n",
    "    Linear,\n",
    "    ChebConv,\n",
    "    SAGEConv,\n",
    "    ASAPooling,\n",
    "    dense_diff_pool,\n",
    "    avg_pool_neighbor_x\n",
    ")\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import to_dense_adj, to_dense_batch\n",
    "\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit.library import U3Gate, CZGate, PhaseGate, CXGate\n",
    "from mbd_utils import construct_random_clifford, cal_z_exp, calc_imbalance, cal_all_z_exp, construct_mbl_circuit, generate_disorder\n",
    "from gnn import ExpValCircuitGraphModel\n",
    "plt.style.use({'figure.facecolor':'white'})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "backend_lima = FakeLima()\n",
    "backend_belem = FakeBelem()\n",
    "backend_montreal = FakeMontreal()\n",
    "properties_lima = get_backend_properties_v1(backend_lima)\n",
    "properties_belem = get_backend_properties_v1(backend_belem)\n",
    "properties_montreal = get_backend_properties_v1(backend_montreal)\n",
    "\n",
    "## Local\n",
    "backend_ideal = QasmSimulator() # Noiseless\n",
    "backend_noisy_lima = AerSimulator.from_backend(backend_lima) # Noisy\n",
    "backend_noisy_belem = AerSimulator.from_backend(backend_belem) # Noisy\n",
    "backend_noisy_montreal = AerSimulator.from_backend(backend_montreal) # Noisy\n",
    "\n",
    "run_config_ideal = {'shots': 10000, 'backend': backend_ideal, 'name': 'ideal'}\n",
    "run_config_noisy_lima = {'shots': 10000, 'backend': backend_noisy_lima, 'name': 'noisy_lima'}\n",
    "run_config_noisy_belem = {'shots': 10000, 'backend': backend_noisy_belem, 'name': 'noisy_belem'}\n",
    "run_config_noisy_montreal = {'shots': 10000, 'backend': backend_noisy_montreal, 'name': 'noisy_montreal'}\n",
    "\n",
    "BATCH_SIZE = 32"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sweep Fintuning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "model_path = './model/finetuning/train_fakelima.pth'\n",
    "\n",
    "model = ExpValCircuitGraphModel(\n",
    "    num_node_features=22,\n",
    "    hidden_channels=15,\n",
    "    exp_value_size=1\n",
    ")\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer,\n",
    "                              'min',\n",
    "                              factor=0.1,\n",
    "                              patience=15,\n",
    "                              verbose=True,\n",
    "                              min_lr=0.00001)\n",
    "\n",
    "finetune_paths = [\n",
    "    f'./data/circ_parsed_pyg_data/finetune/fakemontreal_depth{i}.json' for i in range(1, 10)\n",
    "]\n",
    "\n",
    "test_paths = [\n",
    "    f'./data/circ_parsed_pyg_data/val/fakemontreal_depth{i}.json' for i in range(1, 10)\n",
    "]\n",
    "\n",
    "finetune_loader = DataLoader(\n",
    "    CircuitGraphExpValMitigationDataset(\n",
    "        finetune_paths,\n",
    "        num_samples=300\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    CircuitGraphExpValMitigationDataset(\n",
    "        test_paths,\n",
    "    ),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad), len(finetune_loader) * BATCH_SIZE, len(test_loader) * BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "Model training:   0%|          | 0/50 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "92900c68699f4e24a8966195c0ca5687"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00029: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 00045: reducing learning rate of group 0 to 1.0000e-05.\n"
     ]
    }
   ],
   "source": [
    "min_valid_loss = np.inf\n",
    "\n",
    "finetune_losses = []\n",
    "test_losses = []\n",
    "\n",
    "N_EPOCHS = 50\n",
    "\n",
    "progress = tqdm_notebook(range(N_EPOCHS), desc='Model training', leave=True)\n",
    "for epoch in progress:\n",
    "    finetune_loss = 0.0\n",
    "    model.train()\n",
    "    for i, data in enumerate(finetune_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out = model(\n",
    "            data.noisy_0,\n",
    "            data.observable,\n",
    "            data.circuit_depth,\n",
    "            data.x,\n",
    "            data.edge_index,\n",
    "            data.batch\n",
    "        )\n",
    "        loss = criterion(out, torch.squeeze(data.y, 1))\n",
    "\n",
    "        finetune_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    test_loss = 0.0\n",
    "    model.eval()\n",
    "    for i, data in enumerate(test_loader):\n",
    "        out = model(\n",
    "            data.noisy_0,\n",
    "            data.observable,\n",
    "            data.circuit_depth,\n",
    "            data.x,\n",
    "            data.edge_index,\n",
    "            data.batch)\n",
    "        loss = criterion(out, torch.squeeze(data.y, 1))\n",
    "\n",
    "        test_loss += loss.item()\n",
    "\n",
    "    scheduler.step(test_loss)\n",
    "\n",
    "    if epoch >= 1:\n",
    "        finetune_losses.append(finetune_loss / len(finetune_loader))\n",
    "        test_losses.append(test_loss / len(test_loader))\n",
    "\n",
    "        progress.set_description(f\"{round(finetune_losses[-1], 5)}, {round(test_losses[-1], 5)}\")\n",
    "        progress.refresh()\n",
    "\n",
    "\n",
    "\n",
    "plt.style.use({'figure.facecolor':'white'})\n",
    "plt.plot(finetune_losses, label=\"train_loss\")\n",
    "plt.plot(test_losses, label=\"val_loss\")\n",
    "plt.title('Finetune and test on fakemonreal')\n",
    "plt.yscale('log')\n",
    "plt.ylim([0.0001, 0.5])\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "model_path = './model/finetuning/finetune_fakemontreal.pth'\n",
    "\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "to_save = {'finetune_losses': finetune_losses, 'test_losses': test_losses}\n",
    "with open('.'+model_path.split('.')[1]+'.pk', 'wb') as handle:\n",
    "    pickle.dump(to_save, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# with open('./model/finetuning/finetune_fakemontreal.pk', 'rb') as in_file:\n",
    "#     curves = pickle.load(in_file)\n",
    "#\n",
    "# finetune_losses, test_losses = curves['finetune_losses'], curves['test_losses']"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
