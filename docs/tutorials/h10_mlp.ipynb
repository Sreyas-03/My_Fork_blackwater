{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json, os\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "\n",
    "import qiskit\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.compiler import transpile\n",
    "from qiskit_aer import AerSimulator, QasmSimulator\n",
    "from qiskit.converters import circuit_to_dag, dag_to_circuit\n",
    "from qiskit.quantum_info import SparsePauliOp, Operator\n",
    "from qiskit.circuit.library import CXGate, RXGate, IGate, ZGate\n",
    "from qiskit.providers.fake_provider import FakeMontreal, FakeLima\n",
    "\n",
    "from blackwater.data.utils import (\n",
    "    generate_random_pauli_sum_op,\n",
    "    create_estimator_meas_data,\n",
    "    circuit_to_graph_data_json,\n",
    "    get_backend_properties_v1,\n",
    "    encode_pauli_sum_op,\n",
    "    create_meas_data_from_estimators\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "backend = FakeLima()\n",
    "properties = get_backend_properties_v1(backend)\n",
    "\n",
    "## Local\n",
    "backend_ideal = QasmSimulator() # Noiseless\n",
    "backend_noisy = AerSimulator.from_backend(FakeLima()) # Noisy\n",
    "\n",
    "run_config_ideal = {'shots': 10000, 'backend': backend_ideal, 'name': 'ideal'}\n",
    "run_config_noisy = {'shots': 10000, 'backend': backend_noisy, 'name': 'noisy'}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kj/mfqyg_tj77nf4gt67lvscdkw0000gn/T/ipykernel_76110/4227574046.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for entry in tqdm_notebook(json.load(open(data_file, 'r'))):\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/500 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d04f32c2e3bb44ef9833741b5ead4437"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "def load_circuits(data_dir):\n",
    "    circuits = []\n",
    "    data_files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith('.json')][2:3]\n",
    "    for data_file in data_files:\n",
    "        for entry in tqdm_notebook(json.load(open(data_file, 'r'))):\n",
    "            circuits.append(QuantumCircuit.from_qasm_str(entry['circuit']))\n",
    "    return circuits\n",
    "\n",
    "circuits = load_circuits('./data/mbd_datasets2/theta_0.05pi/train/')\n",
    "print(len(circuits))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([111.3405,  69.8825,  51.4567,  51.4567,  45.1815,  73.5210,  67.5698,\n         62.5218, 112.0000,  98.0000,  24.0000,   0.0000,   0.0000,   0.0000,\n          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   8.0000,\n         14.0000,   0.0000,   8.0000,   0.0000,  21.0000,   1.0000,   0.0000,\n          6.0000,   0.0000,   5.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n          8.0000,  21.0000,   8.0000,   0.0000,   0.0000,  12.0000,   0.0000,\n          0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n          0.0000,   0.0000], dtype=torch.float64)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode_data(circuits, properties):\n",
    "\n",
    "    def recursive_dict_loop(my_dict, parent_key=None, out=[], target_key1=None, target_key2=None):\n",
    "        for key, val in my_dict.items():\n",
    "            if isinstance(val, dict):\n",
    "                recursive_dict_loop(val, key, out, target_key1, target_key2)\n",
    "            else:\n",
    "                if parent_key and target_key1 in str(parent_key) and key == target_key2:\n",
    "                    out += [val]\n",
    "        return out\n",
    "\n",
    "    vec = [np.mean(recursive_dict_loop(properties, target_key1='cx', target_key2='gate_error'))]\n",
    "    vec += [np.mean(recursive_dict_loop(properties, target_key1='id', target_key2='gate_error'))]\n",
    "    vec += [np.mean(recursive_dict_loop(properties, target_key1='sx', target_key2='gate_error'))]\n",
    "    vec += [np.mean(recursive_dict_loop(properties, target_key1='x', target_key2='gate_error'))]\n",
    "    vec += [np.mean(recursive_dict_loop(properties, target_key1='rz', target_key2='gate_error'))]\n",
    "    vec += [np.mean(recursive_dict_loop(properties, target_key1='', target_key2='readout_error'))]\n",
    "    vec += [np.mean(recursive_dict_loop(properties, target_key1='', target_key2='t1'))]\n",
    "    vec += [np.mean(recursive_dict_loop(properties, target_key1='', target_key2='t2'))]\n",
    "    vec = torch.tensor(vec) * 10000 # put it in the same order of magnitude as the number of gates\n",
    "\n",
    "    bin_size = 0.1 * np.pi\n",
    "    num_angle_bins = int(np.ceil(4 * np.pi / bin_size))\n",
    "    X = torch.zeros([len(circuits), len(vec) + 3 + num_angle_bins], dtype=torch.float64)\n",
    "    X[:, :len(vec)] = vec[None, :]\n",
    "\n",
    "    for i, circ in enumerate(circuits):\n",
    "        gate_counts = circ.count_ops()\n",
    "        X[i, len(vec):len(vec)+3] = torch.tensor(\n",
    "            [gate_counts['rz'],  gate_counts['sx'], gate_counts['cx']]\n",
    "        )\n",
    "\n",
    "    def count_gates_by_rotation_angle(circuit):\n",
    "        angles = []\n",
    "        for instr, qargs, cargs in circuit.data:\n",
    "            if instr.name in ['rx', 'ry', 'rz'] and len(qargs) == 1:\n",
    "                angles += [instr.params[0]]\n",
    "        bin_edges = np.arange(-2 * np.pi, 2 * np.pi + bin_size, bin_size)\n",
    "        counts, _ = np.histogram(angles, bins=bin_edges)\n",
    "        bin_labels = [f\"{left:.2f} to {right:.2f}\" for left, right in zip(bin_edges[:-1], bin_edges[1:])]\n",
    "        angle_bins = {label: count for label, count in zip(bin_labels, counts)}\n",
    "        return list(angle_bins.values())\n",
    "\n",
    "    for i, circ in enumerate(circuits):\n",
    "        gate_counts = count_gates_by_rotation_angle(circ)\n",
    "        X[i, len(vec)+3:] = torch.tensor(gate_counts)\n",
    "\n",
    "    return X\n",
    "\n",
    "X = encode_data(circuits, properties)\n",
    "X[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "my_dataset = TensorDataset(torch.Tensor(X), torch.Tensor(y))\n",
    "\n",
    "my_dataloader = DataLoader(my_dataset) # create your dataloader\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "train_data_dir = 'data'  # the directory containing the JSON files\n",
    "train_dataset = JSONDataset(train_data_dir)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_data_dir = 'data'  # the directory containing the JSON files\n",
    "test_dataset = JSONDataset(test_data_dir)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=100000, shuffle=False)\n",
    "\n",
    "model = MLP(input_dim=100, hidden_dim=50, output_dim=10)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(train_dataloader):\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                  .format(epoch+1, num_epochs, i+1, len(train_dataloader), loss.item()))\n",
    "\n",
    "# Evaluate your model on the test set\n",
    "test_inputs = torch.stack([torch.Tensor(d) for d in test_data])\n",
    "test_outputs = model(test_inputs)\n",
    "test_loss =\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
